{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf207c29",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Setup\n",
    "\"\"\"\n",
    "Air Quality Index - Model Training\n",
    "Notebook 2: Building and Training ML Models\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e6336",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: Load Data\n",
    "\"\"\"\n",
    "Load preprocessed data\n",
    "\"\"\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data/processed/aqi_data_explored.csv')\n",
    "\n",
    "# Remove category column if it exists\n",
    "if 'AQI_Category' in df.columns:\n",
    "    df = df.drop('AQI_Category', axis=1)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ada483",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 3: Prepare Data\n",
    "\"\"\"\n",
    "Split features and target, create train/test sets\n",
    "\"\"\"\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('AQI', axis=1)\n",
    "y = df['AQI']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeatures: {list(X.columns)}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"✅ Data prepared and scaled!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e9f0d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 4: Baseline Model\n",
    "\"\"\"\n",
    "Train a simple linear regression as baseline\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BASELINE MODEL: LINEAR REGRESSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "baseline_model = LinearRegression()\n",
    "baseline_model.fit(X_train_scaled, y_train)\n",
    "y_pred_baseline = baseline_model.predict(X_test_scaled)\n",
    "\n",
    "mae_baseline = mean_absolute_error(y_test, y_pred_baseline)\n",
    "rmse_baseline = np.sqrt(mean_squared_error(y_test, y_pred_baseline))\n",
    "r2_baseline = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"MAE:  {mae_baseline:.2f}\")\n",
    "print(f\"RMSE: {rmse_baseline:.2f}\")\n",
    "print(f\"R²:   {r2_baseline:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153b45d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 5: Multiple Models Comparison\n",
    "\"\"\"\n",
    "Train and compare multiple models\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING MULTIPLE MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=1.0),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"  MAE:  {mae:.2f}\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e633d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 6: Model Comparison Visualization\n",
    "\"\"\"\n",
    "Visualize model performance comparison\n",
    "\"\"\"\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'MAE': [results[m]['MAE'] for m in results],\n",
    "    'RMSE': [results[m]['RMSE'] for m in results],\n",
    "    'R2': [results[m]['R2'] for m in results]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "comparison_df.plot(x='Model', y='MAE', kind='bar', ax=axes[0], color='coral', legend=False)\n",
    "axes[0].set_title('Mean Absolute Error', fontweight='bold')\n",
    "axes[0].set_ylabel('MAE')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "comparison_df.plot(x='Model', y='RMSE', kind='bar', ax=axes[1], color='steelblue', legend=False)\n",
    "axes[1].set_title('Root Mean Squared Error', fontweight='bold')\n",
    "axes[1].set_ylabel('RMSE')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "comparison_df.plot(x='Model', y='R2', kind='bar', ax=axes[2], color='green', legend=False)\n",
    "axes[2].set_title('R² Score', fontweight='bold')\n",
    "axes[2].set_ylabel('R²')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('screenshots/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b63a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7: Select Best Model\n",
    "\"\"\"\n",
    "Identify and analyze the best performing model\n",
    "\"\"\"\n",
    "\n",
    "best_model_name = comparison_df.loc[comparison_df['R2'].idxmax(), 'Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"MAE:  {results[best_model_name]['MAE']:.2f}\")\n",
    "print(f\"RMSE: {results[best_model_name]['RMSE']:.2f}\")\n",
    "print(f\"R²:   {results[best_model_name]['R2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae5924",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 8: Hyperparameter Tuning\n",
    "\"\"\"\n",
    "Fine-tune the best model using GridSearchCV\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    \n",
    "    print(\"Performing Grid Search... (this may take a few minutes)\")\n",
    "    grid_search = GridSearchCV(\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Use tuned model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_predictions = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    print(f\"\\nTuned Model Performance:\")\n",
    "    print(f\"MAE:  {mean_absolute_error(y_test, best_predictions):.2f}\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, best_predictions)):.2f}\")\n",
    "    print(f\"R²:   {r2_score(y_test, best_predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb1577",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 9: Cross-Validation\n",
    "\"\"\"\n",
    "Perform cross-validation for robust performance estimate\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CROSS-VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    best_model, X_train_scaled, y_train, \n",
    "    cv=5, scoring='r2'\n",
    ")\n",
    "\n",
    "print(f\"Cross-validation R² scores: {cv_scores}\")\n",
    "print(f\"Mean CV R²: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa2e90",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 10: Save Model\n",
    "\"\"\"\n",
    "Save the trained model for deployment\n",
    "\"\"\"\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save model and scaler\n",
    "joblib.dump(best_model, 'models/random_forest_model.pkl')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "\n",
    "print(\"✅ Model and scaler saved successfully!\")\n",
    "print(\"   - models/random_forest_model.pkl\")\n",
    "print(\"   - models/scaler.pkl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
